{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  score\n",
      "a    Alice     85\n",
      "b      Bob     90\n",
      "c  Charlie     95\n",
      "d    David     80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'score': [85, 90, 95, 80]\n",
    "}, index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name     Alice\n",
       "score       85\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    85\n",
       "b    90\n",
       "c    95\n",
       "d    80\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name     Alice\n",
       "score       85\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      Alice\n",
       "b        Bob\n",
       "c    Charlie\n",
       "d      David\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s the output of this code?\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "print(arr[arr > 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose the correct statements about Python (multiple answers OK)\n",
    "    □ Python uses garbage collection to manage memory\n",
    "    □ Python variables must be declared with a type\n",
    "    □ Python functions can have default arguments\n",
    "    □ Python supports multi-threading without the GIL\n",
    "    □ Python’s with statement is used for context management\n",
    "\n",
    "    1,3,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does this code output?\n",
    "```Python\n",
    "x = [1, 2, 3]\n",
    "y = x\n",
    "x.append(4)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SQL Logic\n",
    "You have a table employees with columns:\n",
    "\n",
    "* id (int)\n",
    "\n",
    "* name (varchar)\n",
    "\n",
    "* salary (float)\n",
    "\n",
    "* department (varchar)\n",
    "\n",
    "Write a SQL query to return the name of the employee(s) with the highest salary per department.\n",
    "\n",
    "```SQL\n",
    "SELECT e.name, e.salary, e.department\n",
    "FROM employees e\n",
    "JOIN (\n",
    "    SELECT department, MAX(salary) AS max_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    ") m ON e.department = m.department AND e.salary = m.max_salary;\n",
    "\n",
    "SELECT e.name, e.salary, e.department\n",
    "FROM employees e\n",
    "WHERE e.salary = (\n",
    "    SELECT MAX(salary)\n",
    "    FROM employees\n",
    "    WHERE department = e.department\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code a function to flatten a nested list.\n",
    "Input:\n",
    "\n",
    "```Python\n",
    "[[1, 2], [3, 4, [5, 6]], 7]\n",
    "\n",
    "Expected output: [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def flatten_it(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            result.extend(flatten_it(item))\n",
    "        else:\n",
    "            result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_it(lst):\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            yield from flatten_it(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1, 2], [3, 4, [5, 6]], 7]\n",
    "\n",
    "list(flatten_it(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What will this code return?\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'group': ['A', 'B', 'A', 'B'],\n",
    "    'value': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "print(df.groupby('group')['value'].sum())\n",
    "\n",
    "□ A: 40, B: 60\n",
    "□ A: 20, B: 60\n",
    "□ A: 30, B: 40\n",
    "□ Error\n",
    "\n",
    "40, 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a Bash command to count the number of lines in a large CSV file that contain the word “ERROR” (case-insensitive).\n",
    "\n",
    "```bash\n",
    "grep -i \"ERROR\" file.csv | wc -l\n",
    "```\n",
    "or without matching lines (just count)\n",
    "```bash\n",
    "grep -i -c \"ERROR\" file.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using requests, write a function that retries 3 times if the API call fails (status != 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_data(url):\n",
    "    try_number = 1\n",
    "    while try_number <= 3:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f'Try #{try_number}: API call failed with status {response.status_code}')\n",
    "            try_number += 1\n",
    "        else:\n",
    "            return response.json()\n",
    "        \n",
    "    raise Exception(f\"API call failed after 3 attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What is the difference between INNER JOIN and LEFT JOIN in SQL? Provide an example if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "\n",
    "SELECT *\n",
    "FROM users\n",
    "INNER JOIN orders ON users.id = orders.user_id;\n",
    "```\n",
    "that will return only users who have placed orders (orders is another table with users_id).\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM users\n",
    "LEFT JOIN orders ON users.id = orders.user_id;\n",
    "```\n",
    "this one returns all users but for those who have not done any order there will be NULL or NAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using Python, how would you find the 5 most common words in a large text file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|      been|   88|\n",
      "|       has|   88|\n",
      "|   dataset|   87|\n",
      "|2023-02-27|   34|\n",
      "|        to|   30|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, col, lower\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('read_file') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.text('./data/HC-5059_ID06-LVP.txt')\n",
    "\n",
    "\n",
    "df_words = df.withColumn('words', split(col('value'), ' '))\n",
    "df_exploded = df_words.select(explode(col('words')).alias('word')) \\\n",
    "                      .withColumn('word', lower(col('word'))) \\\n",
    "                      .filter(col('word') != '')\n",
    "\n",
    "\n",
    "top_words = df_exploded.groupBy('word') \\\n",
    "    .count() \\\n",
    "    .orderBy(col('count').desc()) \\\n",
    "    .limit(5)\n",
    "\n",
    "top_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Which of the following are Python libraries for data manipulation and analysis? (multiple OK)\n",
    "    □ NumPy\n",
    "    □ Pandas\n",
    "    □ TensorFlow\n",
    "    □ SQLAlchemy\n",
    "    □ OpenCV\n",
    "\n",
    "    Pandas, SQLalchemy, numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Write a Python function that reads a JSON file and returns all keys at the top level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_json_keys(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Given the following log line:\n",
    "```pgsql\n",
    "2023-09-10 15:24:02, INFO, Job started by user: admin\n",
    "```\n",
    "Write a regular expression to extract the date, log level, and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def date_log_user(log: str):\n",
    "    pattern = r\"(\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2}, (\\w+), .*user: (\\w+)\"\n",
    "    match = re.search(pattern, log)\n",
    "    if match:\n",
    "        date, level, user = match.groups()\n",
    "        return [date, level, user]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-09-10', 'INFO', 'admin']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = '2023-09-10 15:24:02, INFO, Job started by user: admin'\n",
    "date_log_user(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. What’s the difference between batch and stream processing? When would you use one over the other?\n",
    "\n",
    "In batch Processing data is collected over a period of time and then processed all at once (good for daily reports, dashboards)\n",
    "\n",
    "For Streaming data is collected live (and also processed in real-time) and can be used in IoT, fraud detection, when it is important to make decisions during data accusition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. What’s the difference between a DataFrame and a Series in pandas?\n",
    "\n",
    "Series is 1D, its a labeld 1D array\n",
    "\n",
    "DataFrame is a 2D Table, dictionary of Series with column names as keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Developer in Data & Machine Learning – Technical Test (LLM Focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiple Choice: General Python and ML Concepts\n",
    "Which of the following statements are TRUE? (multiple answers OK)\n",
    "\n",
    "    □ A Python function can return multiple values\n",
    "    □ numpy is often used for data visualization\n",
    "    □ scikit-learn provides tools for deep learning\n",
    "    □ transformers is a library by Hugging Face\n",
    "    □ Tokenization is the process of converting strings into numerical IDs\n",
    "\n",
    "    1, 4, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does the following code print?\n",
    "```python\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\")\n",
    "context = \"Python is a popular programming language created by Guido van Rossum.\"\n",
    "\n",
    "result = qa(question=\"Who created Python?\", context=context)\n",
    "print(result[\"answer\"])\n",
    "```\n",
    "\n",
    "Guido van Rossum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function that takes a text string and returns the most frequent bigram (pair of consecutive words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent_bigram(text):\n",
    "\n",
    "    words = text.lower().split()\n",
    "    bigrams = list(zip(words, words[1:]))\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    most_common = bigram_counts.most_common(1)\n",
    "    \n",
    "    return most_common[0][0] if most_common else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What’s the difference between batch size, epoch, and learning rate in training ML models?\n",
    "\n",
    "batch size is a number of samples the model process at once before update the weights (activation and backpropagation)\n",
    "*   total number of points is 1000 and if batchsize is 100 then the model will do 10 calcultaions/updates\n",
    "-------\n",
    "epoch is total pass through the data pints\n",
    "*   so in the last example all 10 updates would be 1 epoch so multiple epochs are needed for good performance\n",
    "-------\n",
    "learning rate is a coefficient in weights backpropagation:\n",
    "*   small lead to smaler weight changes -> slower training (or no training at all)\n",
    "*   big lead to larger weight updates -> faster training (but can result in not convergency, overshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python: Multiple Choice\n",
    "Which of the following statements are TRUE? (Multiple answers possible)\n",
    "\n",
    "    □ Python supports list, set, and dictionary comprehensions\n",
    "    □ Dictionaries preserve insertion order (Python 3.7+)\n",
    "    □ with open() automatically closes files after reading\n",
    "    □ Tuples are mutable\n",
    "    □ None, False, and 0 are treated the same in conditional checks\n",
    "\n",
    "\n",
    "1, 3, 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File I/O\n",
    "Write a function to read a .csv file and return a list of dictionaries (one per row). Don’t use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv(file_csv):\n",
    "    with open(file_csv, 'r') as file:\n",
    "        rows = [line.strip().split(',') for line in file]\n",
    "        header = rows[0]\n",
    "        values = list(zip(*rows[1:]))\n",
    "        \n",
    "        return dict(zip(header, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def my_read_csv(file_csv):\n",
    "    with open(file_csv, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return [row for row in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JSON Parsing\n",
    "Given the following JSON structure in a file. Write a function that extracts all employee names.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"employees\": [\n",
    "    {\"name\": \"Alice\", \"role\": \"engineer\"},\n",
    "    {\"name\": \"Bob\", \"role\": \"analyst\"}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_employees(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return [employee['name'] for employee in data['employees']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice', 'Bob']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emploees('empl.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL\n",
    "You have a table orders with:\n",
    "\n",
    "order_id\n",
    "\n",
    "user_id\n",
    "\n",
    "order_date\n",
    "\n",
    "amount\n",
    "\n",
    "Write a SQL query to get the total amount spent per user in 2023, ordered from highest to lowest.\n",
    "\n",
    "```sql\n",
    "\n",
    "SELECT user_id, SUM(amount) as total_amount\n",
    "FROM orders\n",
    "WHERE YEAR(order_date) = 2023\n",
    "GROUP BY user_id\n",
    "ORDER BY total_amount DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regex\n",
    "Given the string:\n",
    "```python\n",
    "\"Order #1234 was placed on 2024-05-15 by user ID u678\"\n",
    "```\n",
    "\n",
    "Write a regex to extract:\n",
    "\n",
    "    The order number\n",
    "\n",
    "    The date\n",
    "\n",
    "    The user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def order_info(line):\n",
    "    pattern = 'Order #(\\d+) was placed on (\\d{4}-\\d{2}-\\d{2}) by user ID (\\w+\\d+)'\n",
    "    return [match for match in re.findall(pattern, line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1234', '2024-05-15', 'u678')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_info(\"Order #1234 was placed on 2024-05-15 by user ID u678\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Cleaning\n",
    "Using pandas, write code to:\n",
    "\n",
    "    Load a CSV file with columns name, age, and income\n",
    "\n",
    "    Drop rows with missing age or income\n",
    "\n",
    "    Fill missing names with \"Unknown\"\n",
    "\n",
    "    Convert income to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(file_csv):\n",
    "    data = pd.read_csv(file_csv)\n",
    "    data = data.dropna(subset=['age','income'])\n",
    "    data['name'] = data['name'].fillna('Unknown')\n",
    "    data['income'] = data['income'].astype(float)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dictionaries\n",
    "Write a function that receives a list of strings and returns a dictionary with each unique string as key and its number of occurrences as value.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "[\"apple\", \"banana\", \"apple\"] → {\"apple\": 2, \"banana\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fruits(list_fruits):\n",
    "    result = {}\n",
    "    for fruit in list_fruits:\n",
    "        result[fruit] = result.get(fruit, 0) + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 2, 'banana': 1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_fruits([\"apple\", \"banana\", \"apple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_fruits(list_fruits):\n",
    "    return dict(Counter(list_fruits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. List Comprehension Challenge\n",
    "From a list of integers, return a list of squares of even numbers between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_squared(int_list):\n",
    "    return list(map(lambda x: x**2, filter(lambda x: x % 2 == 0 and x > 0 and x < 100, int_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 64, 4]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_squared([-1, 200, 3, 4, 5, 0, 0, 8, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_squared(int_list):\n",
    "    return [x**2 for x in int_list if x % 2 == 0 and x > 0 and x < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 64, 4]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_squared([-1, 200, 3, 4, 5, 0, 0, 8, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. REST API\n",
    "Use the requests module to send a GET request to:\n",
    "\n",
    "```Python\n",
    "`https://jsonplaceholder.typicode.com/posts`\n",
    "```\n",
    "Write code to fetch the data and print the title of the first 3 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def first_3_titles(url):\n",
    "    response = requests.get(url).json()\n",
    "    return [user['title'] for user in response[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunt aut facere repellat provident occaecati excepturi optio reprehenderit',\n",
       " 'qui est esse',\n",
       " 'ea molestias quasi exercitationem repellat qui ipsa sit aut']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_3_titles('https://jsonplaceholder.typicode.com/posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Command Line Tool (Bonus)\n",
    "Write a script that can be run as:\n",
    "\n",
    "```bash\n",
    "python stats.py data.csv --column=age\n",
    "```\n",
    "It should print the mean, min, and max of the specified column from a CSV.\n",
    "\n",
    "```python\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def get_stats(data, col):\n",
    "    print(f'Statistic for {col}\\nMean: {data[col].mean()}\\nMin: {data[col].min()}\\nMax: {data[col].max()}')\n",
    "\n",
    "def main(input, col):\n",
    "    data = pd.read_csv(input)\n",
    "    get_stats(data, col)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('csv_file', type=str, help='path to the csv file')\n",
    "    parser.add_argument('--column', type=str, required=True, help='select a column')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input = Path(args.csv_file)\n",
    "    col = args.column\n",
    "\n",
    "    main(input, col)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiple Choice: Data Types & Structures\n",
    "Which of the following are mutable types in Python?\n",
    "\n",
    "    □ list\n",
    "    □ dict\n",
    "    □ str\n",
    "    □ set\n",
    "    □ tuple\n",
    "\n",
    "1, 2, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function Logic\n",
    "Write a function that accepts a string and returns True if it’s a valid IPv4 address, otherwise False. Example of valid: \"192.168.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_IP(str_ip):\n",
    "    ip = str_ip.split('.')\n",
    "    if len(ip) != 4:\n",
    "        return False\n",
    "    for number in ip:\n",
    "        if not number.isdigit():\n",
    "            return False\n",
    "        if not 0 <= int(number) <= 255:\n",
    "            return False\n",
    "        if number != '0' and number.startswith('0'):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_valid_IP('16.5.255.2a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CSV Processing\n",
    "You are given a CSV file with the following columns:\n",
    "\n",
    "```python\n",
    "user_id, session_length, timestamp\n",
    "```\n",
    "\n",
    "Write code to:\n",
    "\n",
    "    Load the CSV with pandas\n",
    "\n",
    "    Group by user_id and compute the average session length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_mean_session_length(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    avg_session = data.groupby('user_id')['session_length'].mean()\n",
    "    return avg_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Joining\n",
    "You have two CSVs:\n",
    "\n",
    "users.csv\n",
    "\n",
    "```yaml\n",
    "user_id, name\n",
    "1, Alice\n",
    "2, Bob\n",
    "```\n",
    "\n",
    "logins.csv\n",
    "```yaml\n",
    "user_id, login_time\n",
    "1, 2024-01-01\n",
    "1, 2024-01-02\n",
    "2, 2024-01-01\n",
    "```\n",
    "Write code to merge the data and count logins per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 =pd.DataFrame({'user_id': (1,2), 'name':('Alice', 'Bob')})\n",
    "df2 =pd.DataFrame({'user_id': (1,1,2), 'login_time': ('2024-01-01', '2024-01-02', '2024-01-01')})\n",
    "\n",
    "def merge_count(df_users, df_logins):\n",
    "    login_counts = df_logins.groupby('user_id').size().reset_index(name='total_logins')\n",
    "    result = df_users.merge(login_counts, on='user_id', how='left')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_logins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   name  total_logins\n",
       "0        1  Alice             2\n",
       "1        2    Bob             1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_count(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. String Handling\n",
    "Write a function that takes a sentence and returns the number of unique words, case-insensitive, ignoring punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def number_unique_words(input_str):\n",
    "    words = re.findall(r'\\b\\w+\\b', input_str.lower())\n",
    "    return len(set(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_unique_words('hello? ho.w are you!!a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SQL\n",
    "Given table files with:\n",
    "\n",
    "filename\n",
    "\n",
    "size_kb\n",
    "\n",
    "upload_date\n",
    "\n",
    "Write a SQL query to return the average file size per month in 2024.\n",
    "\n",
    "```sql\n",
    "SELECT AVG(size_kb) as average_size, MONTH(upload_date) as upload_month\n",
    "FROM files\n",
    "WHERE YEAR(upload_date) = 2024\n",
    "GROUP BY upload_month\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time & Date\n",
    "\n",
    "Using Python's datetime module, write a function that returns the number of weekdays between two given dates (as strings in \"YYYY-MM-DD\" format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = '2024-02-04'\n",
    "end = '2024-05-04'\n",
    "print(datetime.datetime(int(start.split('-')[0]),int(start.split('-')[1]),int(start.split('-')[2])))\n",
    "\n",
    "# def get_weekdays(start, end):\n",
    "#     datetime.datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2024, 2, 4]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x) for x in start.split('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def count_weekdays(start_date: str, end_date: str):\n",
    "\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "\n",
    "    weekday_count = 0\n",
    "    current_day = start\n",
    "    \n",
    "    while current_day <= end:\n",
    "        if current_day.weekday() < 5:\n",
    "            weekday_count += 1\n",
    "        current_day += timedelta(days=1)\n",
    "    \n",
    "    return weekday_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 1: Navigation & Files\n",
    "\n",
    "\n",
    "    1. Show your current directory path\n",
    "```bash\n",
    "    pwd\n",
    "```\n",
    "    2. Create a directory called bash_practice and move into it\n",
    "```bash\n",
    "    mkdir bash_practice && cd bash_practice\n",
    "```\n",
    "    3. Inside bash_practice, create an empty file named log.txt\n",
    "```bash\n",
    "    touch log.txt\n",
    "```\n",
    "    4. Copy log.txt to a new file called log_backup.txt\n",
    "```bash\n",
    "    cp log.txt log_backup.txt\n",
    "```\n",
    "    5. Rename log.txt to main_log.txt\n",
    "```bash\n",
    "    mv log.txt main_log.txt\n",
    "```\n",
    "    6. Remove the log_backup.txt file\n",
    "```bash\n",
    "    rm log_backup.txt\n",
    "```\n",
    "    7. Go one directory up and remove the bash_practice folder and everything inside\n",
    "```bash\n",
    "    cd .. && rm -r bash_practice/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 2: Variables & Printing\n",
    "\n",
    "Create a variable called city and assign it your favorite city\n",
    "→ Then print: \"I want to visit (city)\"\n",
    "```bash\n",
    "    city='London'&& echo \"I want to visit $city\"\n",
    "```\n",
    "Create two variables, first=\"Dmitrii\" and last=\"Ivanov\"\n",
    "→ Then print: \"Hello, Dmitrii Ivanov!\" (using those variables)\n",
    "\n",
    "```bash\n",
    "    first='Dmitrii' && last='Ivanov' && echo \"Hello, $first $last!\"\n",
    "```\n",
    "\n",
    "Try using echo with a command substitution\n",
    "→ Print the current date with this structure:\n",
    "\"Today is: (current date)\"\n",
    "\n",
    "```bash\n",
    "    echo \"Today is $(date)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 3: Conditionals & Loops\n",
    "\n",
    "    1. Conditionals\n",
    "Ask the user for their favorite programming language. If they say \"Python\", print \"Good choice!\". Otherwise, print \"Try Python, it’s awesome!\"\n",
    "\n",
    "```bash\n",
    "read lang\n",
    "if [ \"$lang\" == \"Python\" ]; then \n",
    "echo \"Good choice!\"\n",
    "else echo \"Try Python, it's awesome!\"\n",
    "fi\n",
    "```\n",
    "    2. For loop\n",
    "Write a loop that prints the numbers from 5 to 1 (in reverse)\n",
    "Hint: use {5..1} with a step\n",
    "\n",
    "```bash\n",
    "for i in {5..1..-1}; do\n",
    "echo \"Number $i\"\n",
    "done\n",
    "```\n",
    "    3. While loop\n",
    "Create a while loop that counts from 1 to 3 and prints \"Counting: X\"\n",
    "```bash\n",
    "counter=1\n",
    "while [ $counter -le 3 ]; do\n",
    "echo \"Counting: $counter\"\n",
    "((counter++))\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 4: Simple Bash Script\n",
    "\n",
    "Create a file called greet.sh\n",
    "\n",
    "Add the following logic inside:\n",
    "\n",
    "    Ask the user for their name\n",
    "\n",
    "If the name is Dmitrii, print: \"Welcome back, Dmitrii!\"\n",
    "\n",
    "Else, print: \"Hello, (name)!\"\n",
    "\n",
    "    Make it executable and run it\n",
    "\n",
    "```bash\n",
    "    touch greet.sh && printf '#!/bin/bash\\necho \"What'\\''s your name?\"\\nread name\\nif [ \"$name\" == \"Dmitrii\" ]; then\\n  echo \"Welcome back, Dmitrii!\"\\nelse\\n  echo \"Hello $name!\"\\nfi\\n' > greet.sh && chmod +x greet.sh && ./greet.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Tools Exercises\n",
    "\n",
    "```bash\n",
    "cat <<EOF > sample.txt\n",
    "Name Age Score\n",
    "Alice 30 85\n",
    "Bob 25 92\n",
    "Charlie 35 78\n",
    "Dmitrii 34 100\n",
    "Eve 28 66\n",
    "EOF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grep Challenges\n",
    "    Find all lines that contain the name Dmitrii\n",
    "```bash\n",
    "    grep \"Dmitrii\" sample.txt\n",
    "```\n",
    "    Find all lines with a score of at least 9 (just try grep without regex for now)\n",
    "```bash\n",
    "    awk '$3 >= 90 {print $0}' sample.txt\n",
    "\n",
    "    grep -E \"9[0-9]|100\" sample.txt\n",
    "```\n",
    "    Find all lines that contain names with capital C\n",
    "```bash\n",
    "    grep \"\\bC\" sample.txt\n",
    "\n",
    "    grep \"^C\" sample.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sed Challenges\n",
    "\n",
    "    Replace the name Bob with Robert\n",
    "```bash\n",
    "sed 's/Bob/Robert/' sample.txt\n",
    "```\n",
    "    Delete the first line of the file\n",
    "```bash\n",
    "sed '1d' sample.txt\n",
    "```\n",
    "    Replace all spaces with commas (CSV format!)\n",
    "```bash\n",
    "sed 's/ /,/g' sample.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## awk Challenges\n",
    "\n",
    "    Print only the names\n",
    "```bash\n",
    "awk '{print $1}' sample.txt\n",
    "```\n",
    "    Print names and scores of people with a score above 80\n",
    "```bash\n",
    "awk '$3 > 80 {print $1, $3}' sample.txt\n",
    "```\n",
    "    Print all names and add 10 years to their age\n",
    "```bash\n",
    "awk '{print $1, $2 + 10}' sample.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combo Challenge: Clean + Filter + Transform\n",
    "\n",
    "You have a file called people.txt with messy data:\n",
    "\n",
    "```bash\n",
    "#name age score\n",
    " Alice   30   85\n",
    "Bob 25 92\n",
    " Charlie 35 78\n",
    "Dmitrii 34 100\n",
    "Eve  28   66\n",
    "Dan   23 88\n",
    "```\n",
    "    Remove the header line (the one starting with #)\n",
    "\n",
    "    Trim all extra spaces (make fields nicely separated by a single space)\n",
    "\n",
    "    Keep only the people whose names start with D\n",
    "\n",
    "    Add 5 years to their age\n",
    "\n",
    "    Convert the output to a CSV format: Name,NewAge,Score\n",
    "    \n",
    "```bash\n",
    "sed -E -e '1d' -e 's/^ *//g' -e 's/  +/ /g' -n -e '/^D/p' people.txt | awk '{print $1 \",\" $2+5 \",\" $3}' \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASH Exercise #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Log Analyzer\n",
    "File: server.log\n",
    "\n",
    "```sql\n",
    "[INFO] 2024-04-01 Server started\n",
    "[ERROR] 2024-04-01 Failed to connect to DB\n",
    "[WARNING] 2024-04-02 Low disk space\n",
    "[ERROR] 2024-04-03 Timeout on port 8080\n",
    "[INFO] 2024-04-03 Connection restored\n",
    "```\n",
    "\n",
    "```bash\n",
    "cat <<EOF > server.log\n",
    "[INFO] 2024-04-01 Server started\n",
    "[ERROR] 2024-04-01 Failed to connect to DB\n",
    "[WARNING] 2024-04-02 Low disk space\n",
    "[ERROR] 2024-04-03 Timeout on port 8080\n",
    "[INFO] 2024-04-03 Connection restored\n",
    "EOF\n",
    "```\n",
    "\n",
    "* Extract only the lines with [ERROR]\n",
    "\n",
    "```bash\n",
    "grep \"ERROR\" server.log\n",
    "```\n",
    "* Count how many error lines there are\n",
    "```bash\n",
    "grep -c \"ERROR\" server.log\n",
    "\n",
    "grep \"ERROR\" server.log | wc -l\n",
    "```\n",
    "* Extract the date and message from each error line in CSV format like: 2024-04-01,Failed to connect to DB\n",
    "```bash\n",
    "grep \"ERROR\" server.log | sed -E 's/.* ([0-9-]+) (.*)/\\1,\\2/'\n",
    "\n",
    "awk '/ERROR/ {print $2 \",\" substr($0, index($0,$3))}' server.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASH exercise #2\n",
    "## Temperature Monitor\n",
    "File: temps.txt\n",
    "```sql\n",
    "2024-04-01 23°C  \n",
    "2024-04-02 19°C  \n",
    "2024-04-03 28°C  \n",
    "2024-04-04 16°C  \n",
    "2024-04-05 21°C\n",
    "```\n",
    "to create:\n",
    "```bash\n",
    "cat <<EOF > temps.txt\n",
    "2024-04-01 23°C\n",
    "2024-04-02 19°C\n",
    "2024-04-03 28°C\n",
    "2024-04-04 16°C\n",
    "2024-04-05 21°C\n",
    "EOF\n",
    "```\n",
    "\n",
    "*   Extract lines where the temperature is below 20°C\n",
    "```bash\n",
    "sed -E 's/°C//g' temps.txt | awk '$2 < 20 {print $0}'\n",
    "```\n",
    "*   Output only the date and temperature (without the °C), in CSV format:\n",
    "Example: 2024-04-02,19\n",
    "```bash\n",
    "sed -E 's/°C//g' temps.txt | awk '{print $1 \",\" $2}'\n",
    "```\n",
    "*   Count how many cold days (<20°C)\n",
    "```bash\n",
    "sed -E 's/°C//g' temps.txt | awk '$2 < 20 {print $0}' | wc -l\n",
    "\n",
    "awk '{gsub(\"°C\",\"\"); if ($2 < 20) count++} END {print count}' temps.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
