{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  score\n",
      "a    Alice     85\n",
      "b      Bob     90\n",
      "c  Charlie     95\n",
      "d    David     80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'score': [85, 90, 95, 80]\n",
    "}, index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name     Alice\n",
       "score       85\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    85\n",
       "b    90\n",
       "c    95\n",
       "d    80\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name     Alice\n",
       "score       85\n",
       "Name: a, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      Alice\n",
       "b        Bob\n",
       "c    Charlie\n",
       "d      David\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s the output of this code?\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "print(arr[arr > 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose the correct statements about Python (multiple answers OK)\n",
    "    □ Python uses garbage collection to manage memory\n",
    "    □ Python variables must be declared with a type\n",
    "    □ Python functions can have default arguments\n",
    "    □ Python supports multi-threading without the GIL\n",
    "    □ Python’s with statement is used for context management\n",
    "\n",
    "    1,3,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does this code output?\n",
    "```Python\n",
    "x = [1, 2, 3]\n",
    "y = x\n",
    "x.append(4)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SQL Logic\n",
    "You have a table employees with columns:\n",
    "\n",
    "* id (int)\n",
    "\n",
    "* name (varchar)\n",
    "\n",
    "* salary (float)\n",
    "\n",
    "* department (varchar)\n",
    "\n",
    "Write a SQL query to return the name of the employee(s) with the highest salary per department.\n",
    "\n",
    "```SQL\n",
    "SELECT e.name, e.salary, e.department\n",
    "FROM employees e\n",
    "JOIN (\n",
    "    SELECT department, MAX(salary) AS max_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    ") m ON e.department = m.department AND e.salary = m.max_salary;\n",
    "\n",
    "SELECT e.name, e.salary, e.department\n",
    "FROM employees e\n",
    "WHERE e.salary = (\n",
    "    SELECT MAX(salary)\n",
    "    FROM employees\n",
    "    WHERE department = e.department\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code a function to flatten a nested list.\n",
    "Input:\n",
    "\n",
    "```Python\n",
    "[[1, 2], [3, 4, [5, 6]], 7]\n",
    "\n",
    "Expected output: [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def flatten_it(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            result.extend(flatten_it(item))\n",
    "        else:\n",
    "            result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_it(lst):\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            yield from flatten_it(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1, 2], [3, 4, [5, 6]], 7]\n",
    "\n",
    "list(flatten_it(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What will this code return?\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'group': ['A', 'B', 'A', 'B'],\n",
    "    'value': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "print(df.groupby('group')['value'].sum())\n",
    "\n",
    "□ A: 40, B: 60\n",
    "□ A: 20, B: 60\n",
    "□ A: 30, B: 40\n",
    "□ Error\n",
    "\n",
    "40, 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a Bash command to count the number of lines in a large CSV file that contain the word “ERROR” (case-insensitive).\n",
    "\n",
    "```bash\n",
    "grep -i \"ERROR\" file.csv | wc -l\n",
    "```\n",
    "or without matching lines (just count)\n",
    "```bash\n",
    "grep -i -c \"ERROR\" file.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using requests, write a function that retries 3 times if the API call fails (status != 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_data(url):\n",
    "    try_number = 1\n",
    "    while try_number <= 3:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f'Try #{try_number}: API call failed with status {response.status_code}')\n",
    "            try_number += 1\n",
    "        else:\n",
    "            return response.json()\n",
    "        \n",
    "    raise Exception(f\"API call failed after 3 attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What is the difference between INNER JOIN and LEFT JOIN in SQL? Provide an example if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "\n",
    "SELECT *\n",
    "FROM users\n",
    "INNER JOIN orders ON users.id = orders.user_id;\n",
    "```\n",
    "that will return only users who have placed orders (orders is another table with users_id).\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM users\n",
    "LEFT JOIN orders ON users.id = orders.user_id;\n",
    "```\n",
    "this one returns all users but for those who have not done any order there will be NULL or NAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using Python, how would you find the 5 most common words in a large text file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|      been|   88|\n",
      "|       has|   88|\n",
      "|   dataset|   87|\n",
      "|2023-02-27|   34|\n",
      "|        to|   30|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, col, lower\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('read_file') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.text('./data/HC-5059_ID06-LVP.txt')\n",
    "\n",
    "\n",
    "df_words = df.withColumn('words', split(col('value'), ' '))\n",
    "df_exploded = df_words.select(explode(col('words')).alias('word')) \\\n",
    "                      .withColumn('word', lower(col('word'))) \\\n",
    "                      .filter(col('word') != '')\n",
    "\n",
    "\n",
    "top_words = df_exploded.groupBy('word') \\\n",
    "    .count() \\\n",
    "    .orderBy(col('count').desc()) \\\n",
    "    .limit(5)\n",
    "\n",
    "top_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Which of the following are Python libraries for data manipulation and analysis? (multiple OK)\n",
    "    □ NumPy\n",
    "    □ Pandas\n",
    "    □ TensorFlow\n",
    "    □ SQLAlchemy\n",
    "    □ OpenCV\n",
    "\n",
    "    Pandas, SQLalchemy, numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Write a Python function that reads a JSON file and returns all keys at the top level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_json_keys(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Given the following log line:\n",
    "```pgsql\n",
    "2023-09-10 15:24:02, INFO, Job started by user: admin\n",
    "```\n",
    "Write a regular expression to extract the date, log level, and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def date_log_user(log: str):\n",
    "    pattern = r\"(\\d{4}-\\d{2}-\\d{2}) \\d{2}:\\d{2}:\\d{2}, (\\w+), .*user: (\\w+)\"\n",
    "    match = re.search(pattern, log)\n",
    "    if match:\n",
    "        date, level, user = match.groups()\n",
    "        return [date, level, user]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-09-10', 'INFO', 'admin']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = '2023-09-10 15:24:02, INFO, Job started by user: admin'\n",
    "date_log_user(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. What’s the difference between batch and stream processing? When would you use one over the other?\n",
    "\n",
    "In batch Processing data is collected over a period of time and then processed all at once (good for daily reports, dashboards)\n",
    "\n",
    "For Streaming data is collected live (and also processed in real-time) and can be used in IoT, fraud detection, when it is important to make decisions during data accusition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. What’s the difference between a DataFrame and a Series in pandas?\n",
    "\n",
    "Series is 1D, its a labeld 1D array\n",
    "\n",
    "DataFrame is a 2D Table, dictionary of Series with column names as keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Developer in Data & Machine Learning – Technical Test (LLM Focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiple Choice: General Python and ML Concepts\n",
    "Which of the following statements are TRUE? (multiple answers OK)\n",
    "\n",
    "    □ A Python function can return multiple values\n",
    "    □ numpy is often used for data visualization\n",
    "    □ scikit-learn provides tools for deep learning\n",
    "    □ transformers is a library by Hugging Face\n",
    "    □ Tokenization is the process of converting strings into numerical IDs\n",
    "\n",
    "    1, 4, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does the following code print?\n",
    "```python\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\")\n",
    "context = \"Python is a popular programming language created by Guido van Rossum.\"\n",
    "\n",
    "result = qa(question=\"Who created Python?\", context=context)\n",
    "print(result[\"answer\"])\n",
    "```\n",
    "\n",
    "Guido van Rossum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function that takes a text string and returns the most frequent bigram (pair of consecutive words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent_bigram(text):\n",
    "\n",
    "    words = text.lower().split()\n",
    "    bigrams = list(zip(words, words[1:]))\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    most_common = bigram_counts.most_common(1)\n",
    "    \n",
    "    return most_common[0][0] if most_common else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What’s the difference between batch size, epoch, and learning rate in training ML models?\n",
    "\n",
    "batch size is a number of samples the model process at once before update the weights (activation and backpropagation)\n",
    "*   total number of points is 1000 and if batchsize is 100 then the model will do 10 calcultaions/updates\n",
    "-------\n",
    "epoch is total pass through the data pints\n",
    "*   so in the last example all 10 updates would be 1 epoch so multiple epochs are needed for good performance\n",
    "-------\n",
    "learning rate is a coefficient in weights backpropagation:\n",
    "*   small lead to smaler weight changes -> slower training (or no training at all)\n",
    "*   big lead to larger weight updates -> faster training (but can result in not convergency, overshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
